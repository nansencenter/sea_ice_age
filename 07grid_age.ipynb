{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07384149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from multiprocessing import Pool\n",
    "import tqdm\n",
    "import gc\n",
    "from scipy.interpolate import griddata\n",
    "import numpy as np\n",
    "from matplotlib.tri import Triangulation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0cac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:34: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_1533982/118886125.py:34: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  '''\n"
     ]
    }
   ],
   "source": [
    "def jacobian(x0, y0, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    jac = jacobian(x0, y0, x1, y1, x2, y2):\n",
    "    calculates jac = det(M),\n",
    "    where M is the matrix\n",
    "    [[x1-x0, y1-y0], [x2-x0, y2-y0]].\n",
    "\n",
    "    This is twice the area of a triangle with vertices:\n",
    "    (x0, y0), (x1, y1), (x2, y2)\n",
    "\n",
    "    Parameters:\n",
    "    x0, x1, x2 (numpy arrays or floats) - x coords of the 3 points\n",
    "    y0, y1, y2 (numpy arrays or floats) - y coords of the 3 points\n",
    "\n",
    "    Returns:\n",
    "    jac (same type as inputs)\n",
    "    \"\"\"\n",
    "    return (x1-x0)*(y2-y0)-(x2-x0)*(y1-y0)\n",
    "\n",
    "def measure(x, y, t):\n",
    "    dx = np.diff(np.hstack([x[t], x[t][:,0][None].T]))\n",
    "    dy = np.diff(np.hstack([y[t], y[t][:,0][None].T]))\n",
    "    edges = np.hypot(dx, dy)\n",
    "    perim = edges.sum(axis=1)\n",
    "    area = get_area(x, y, t)\n",
    "    ap_ratio = area**0.5/ perim\n",
    "    return area, edges, perim, ap_ratio\n",
    "\n",
    "def get_area(x, y, t):\n",
    "    return .5*jacobian(x[t][:,0], y[t][:,0], x[t][:,1], y[t][:,1], x[t][:,2], y[t][:,2])\n",
    "\n",
    "class IrregularGridInterpolator(object):\n",
    "    def __init__(self, x0, y0, x1, y1, triangles=None):\n",
    "        '''\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x0 : np.ndarray(float)\n",
    "            x-coords of source points\n",
    "        y0 : np.ndarray(float)\n",
    "            y-coords of source points\n",
    "        x1 : np.ndarray(float)\n",
    "            x-coords of destination points\n",
    "        y1 : np.ndarray(float)\n",
    "            y-coords of destination points\n",
    "        triangles : np.ndarray(int)\n",
    "            shape (num_triangles, 3)\n",
    "            indices of nodes for each triangle\n",
    "\n",
    "        Sets:\n",
    "        -----\n",
    "        self.inside: np.ndarray(bool)\n",
    "            shape = (num_target_points,)\n",
    "        self.vertices: np.ndarray(int)\n",
    "            shape = (num_good_target_points, 3)\n",
    "            good target points are those inside the source triangulation\n",
    "        self.weights: np.ndarray(float)\n",
    "            shape = (num_good_target_points, 3)\n",
    "            good target points are those inside the source triangulation\n",
    "\n",
    "        Follows this suggestion:\n",
    "        https://stackoverflow.com/questions/20915502/speedup-scipy-griddata-for-multiple-interpolations-between-two-irregular-grids\n",
    "        x_target[i] = \\sum_{j=0}^2 weights[i, j]*x_source[vertices[i, j]]\n",
    "        y_target[i] = \\sum_{j=0}^2 weights[i, j]*y_source[vertices[i, j]]\n",
    "        We can do (linear) interpolation by replacing x_target, x_source with z_target, z_source\n",
    "        where z_source is the field to be interpolated and z_target is the interpolated field\n",
    "        '''\n",
    "\n",
    "        # define and triangulate source points\n",
    "        self.src_shape = x0.shape\n",
    "        self.src_points = np.array([x0.flatten(), y0.flatten()]).T\n",
    "        self.tri = Triangulation(x0.flatten(), y0.flatten(), triangles=triangles)\n",
    "        self.tri_finder = self.tri.get_trifinder()\n",
    "        self.num_triangles = len(self.tri.triangles)\n",
    "        self._set_transform()\n",
    "\n",
    "        # define target points\n",
    "        self.dst_points = np.array([x1.flatten(), y1.flatten()]).T\n",
    "        self.dst_shape = x1.shape\n",
    "        self.triangle_map = self.tri_finder(x1, y1)\n",
    "        self.dst_mask = (self.triangle_map < 0)\n",
    "        self.triangle_map[self.dst_mask] = 0\n",
    "        self.inside = ~self.dst_mask.flatten()\n",
    "\n",
    "        \"\"\"\n",
    "        get barycentric coords\n",
    "        https://en.wikipedia.org/wiki/Barycentric_coordinate_system#Barycentric_coordinates_on_triangles\n",
    "        each row of bary is (lambda_1, lambda_2) for 1 destination point\n",
    "        \"\"\"\n",
    "        d = 2\n",
    "        inds = self.triangle_map.flatten()[self.inside]\n",
    "        self.vertices = np.take(self.tri.triangles, inds, axis=0)\n",
    "        temp = np.take(self.transform, inds, axis=0)\n",
    "        delta = self.dst_points[self.inside] - temp[:, d]\n",
    "        bary = np.einsum('njk,nk->nj', temp[:, :d, :], delta)\n",
    "\n",
    "        # set weights\n",
    "        self.weights = np.hstack((bary, 1 - bary.sum(axis=1, keepdims=True)))\n",
    "\n",
    "    def _set_transform(self):\n",
    "        \"\"\"\n",
    "        Used for getting the barycentric coordinates on a triangle.\n",
    "        Follows:\n",
    "        https://en.wikipedia.org/wiki/Barycentric_coordinate_system#Barycentric_coordinates_on_triangles\n",
    "\n",
    "        Sets:\n",
    "        -----\n",
    "        self.transform : numpy.ndarray\n",
    "            For the i-th triangle,\n",
    "                self.transform[i] = [[a', b'], [c', d'], [x_3, y3]]\n",
    "            where the first 2 rows are the inverse of the matrix T in the wikipedia link\n",
    "            and (x_3, y_3) are the coordinates of the 3rd vertex of the triangle\n",
    "        \"\"\"\n",
    "        x = self.tri.x[self.tri.triangles]\n",
    "        y = self.tri.y[self.tri.triangles]\n",
    "        a = x[:,0] - x[:,2]\n",
    "        b = x[:,1] - x[:,2]\n",
    "        c = y[:,0] - y[:,2]\n",
    "        d = y[:,1] - y[:,2]\n",
    "        det = a*d-b*c\n",
    "\n",
    "        self.transform = np.zeros((self.num_triangles, 3, 2))\n",
    "        self.transform[:,0,0] = d/det\n",
    "        self.transform[:,0,1] = -b/det\n",
    "        self.transform[:,1,0] = -c/det\n",
    "        self.transform[:,1,1] = a/det\n",
    "        self.transform[:,2,0] = x[:,2]\n",
    "        self.transform[:,2,1] = y[:,2]\n",
    "\n",
    "    def interp_field(self, fld, method='linear'):\n",
    "        \"\"\"\n",
    "        Interpolate field from elements elements or nodes of source triangulation\n",
    "        to destination points\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        fld: np.ndarray\n",
    "            field to be interpolated\n",
    "        method : str\n",
    "            interpolation method if interpolating from nodes\n",
    "            - 'linear'  : linear interpolation\n",
    "            - 'nearest' : nearest neighbour\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "        fld_interp : np.ndarray\n",
    "            field interpolated onto the destination points\n",
    "        \"\"\"\n",
    "        if fld.shape == self.src_shape:\n",
    "            return self._interp_nodes(fld, method=method)\n",
    "        fld_ = fld.flatten()\n",
    "        if len(fld_) == self.num_triangles:\n",
    "            return self._interp_elements(fld_)\n",
    "        msg = f\"\"\"Field to interpolate should have the same size as the source points\n",
    "        i.e. {self.src_shape}, or be a vector with the same number of triangles\n",
    "        as the source triangulation i.e. self.num_triangles\"\"\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    def _interp_elements(self, fld):\n",
    "        \"\"\"\n",
    "        Interpolate field from elements of source triangulation to destination points\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        fld: np.ndarray\n",
    "            field to be interpolated\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "        fld_interp : np.ndarray\n",
    "            field interpolated onto the destination points\n",
    "        \"\"\"\n",
    "        fld_interp = fld[self.triangle_map]\n",
    "        fld_interp[self.dst_mask] = np.nan\n",
    "        return fld_interp\n",
    "\n",
    "    def _interp_nodes(self, fld, method='linear'):\n",
    "        \"\"\"\n",
    "        Interpolate field from nodes of source triangulation to destination points\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        fld: np.ndarray\n",
    "            field to be interpolated\n",
    "        method : str\n",
    "            interpolation method\n",
    "            - 'linear'  : linear interpolation\n",
    "            - 'nearest' : nearest neighbour\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "        fld_interp : np.ndarray\n",
    "            field interpolated onto the destination points\n",
    "        \"\"\"\n",
    "        ndst = self.dst_points.shape[0]\n",
    "        fld_interp = np.full((ndst,), np.nan)\n",
    "        w = self.weights\n",
    "        if method == 'linear':\n",
    "            # sum over the weights for each node of triangle\n",
    "            v = self.vertices # shape = (ngood,3)\n",
    "            fld_interp[self.inside] = np.einsum(\n",
    "                    'nj,nj->n', np.take(fld.flatten(), v), w)\n",
    "\n",
    "        elif method == 'nearest':\n",
    "            # find the node of the triangle with the maximum weight\n",
    "            v = np.array(self.vertices) # shape = (ngood,3)\n",
    "            v = v[np.arange(len(w), dtype=int), np.argmax(w, axis=1)] # shape = (ngood,)\n",
    "            fld_interp[self.inside] = fld.flatten()[v]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"'method' should be 'nearest' or 'linear'\")\n",
    "\n",
    "        return fld_interp.reshape(self.dst_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bff5017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean as cm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "land_50m = cfeature.LAND\n",
    "sid_srs = ccrs.LambertAzimuthalEqualArea(central_longitude=0, central_latitude=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94966fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "force = False\n",
    "lag_dir = '/data2/Anton/sia/cdr_1991_2023'\n",
    "dst_dir = f'{lag_dir}/age'\n",
    "\n",
    "mesh_init_file = 'mesh_arctic_ease_25km_max7.npz'\n",
    "xc = np.load(mesh_init_file)['xc']\n",
    "yc = np.load(mesh_init_file)['yc'][::-1]\n",
    "mask = np.load(mesh_init_file)['mask']\n",
    "xgrd, ygrd = np.meshgrid(xc, yc)\n",
    "\n",
    "sic = np.load('/Data/sim/data/OSISAF_ice_drift_CDR_postproc/1991/ice_drift_nh_ease2-750_cdr-v1p0_24h-199101011200.nc.npz')['c']\n",
    "landmask = np.isnan(sic).astype(float)\n",
    "landmask[landmask == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad9f1415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731 /data2/Anton/sia/cdr_1991_2023/age/2023/age_20230311.npz /data2/Anton/sia/cdr_1991_2023/age/2025/age_20250310.npz\n"
     ]
    }
   ],
   "source": [
    "age_files = sorted(glob.glob(f'{dst_dir}/*/age_????????.npz'))[11500:]\n",
    "print(len(age_files), age_files[0], age_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4ddf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:41<00:00, 17.83it/s] \n"
     ]
    }
   ],
   "source": [
    "def grid_age(age_file):\n",
    "    age_grd_file = age_file.replace('.npz', '_grd.npz').replace('/age/', '/age_grd/')\n",
    "    if os.path.exists(age_grd_file) and not force:\n",
    "        return\n",
    "    try:\n",
    "        t = np.load(age_file)['t']\n",
    "        x = np.load(age_file)['x']\n",
    "        y = np.load(age_file)['y']\n",
    "        a = np.load(age_file)['a']\n",
    "        f = np.load(age_file)['f']\n",
    "    except:\n",
    "        raise ValueError(f'Cannot load from {age_file}')\n",
    "\n",
    "    try:\n",
    "        igi = IrregularGridInterpolator(x, y, xgrd, ygrd, t)\n",
    "    except:\n",
    "        raise ValueError(f'Cannot create IGI {age_file}')\n",
    "\n",
    "    src_data = np.vstack([a[None], f])\n",
    "    dst_data = []\n",
    "    for d in src_data:\n",
    "        try:\n",
    "            dgrd = igi.interp_field(d)\n",
    "        except:\n",
    "            raise ValueError(f'Cannot interpolate {age_file}')\n",
    "        dgrd[mask == 0] = np.nan\n",
    "        dst_data.append(dgrd.astype(np.float32))\n",
    "\n",
    "    save_data = dict(age=dst_data.pop(0))\n",
    "    frac_num = len(dst_data)\n",
    "    for i, f in enumerate(dst_data):\n",
    "        save_data[f'fraction_{frac_num - i}yi'] = f\n",
    "    dst_date_dir = os.path.split(age_grd_file)[0]\n",
    "    os.makedirs(dst_date_dir, exist_ok=True)\n",
    "    np.savez_compressed(age_grd_file, **save_data)\n",
    "\n",
    "with Pool(4) as p:\n",
    "    r = list(tqdm.tqdm(p.imap(grid_age, age_files), total=len(age_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776fcc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "age_grd_files = sorted(glob.glob(f'{dst_dir}_grd/*/age_????????_grd.npz'))[::10]\n",
    "print(len(age_grd_files))\n",
    "\n",
    "def plot_age_grd(i_age_grd_file):\n",
    "    i, age_grd_file = i_age_grd_file\n",
    "    dst_png_file = f'{dst_dir}/frame_grd_{i:04}.png'\n",
    "    #if os.path.exists(dst_png_file):\n",
    "    #    return\n",
    "    age = np.load(age_grd_file)['age']\n",
    "    age[mask == 0] = np.nan\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = plt.axes((0,0,1,1), projection=sid_srs)\n",
    "    clim = [0, 5]\n",
    "    cmap = 'jet'\n",
    "    alpha = 1\n",
    "    extent = np.array([xc.min(), xc.max(), yc.min(), yc.max()])*1000\n",
    "    imsh = ax.imshow(age, extent=extent, clim=clim, cmap=cmap, zorder=0, alpha=alpha, interpolation='nearest')\n",
    "    ax.add_feature(land_50m, edgecolor='black', zorder=10)\n",
    "    xlim = (-2000000, 2200000)\n",
    "    ylim = (-2200000, 2700000)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    fig.colorbar(imsh, ax=ax, shrink=0.7)\n",
    "    datestr = os.path.basename(age_grd_file).split('_')[1]\n",
    "    plt.text(-1900000, 2200000, f'{datestr[:4]}-{datestr[4:6]}-{datestr[6:]}', zorder=10, fontsize=14)\n",
    "    plt.savefig(dst_png_file, bbox_inches='tight', pad_inches=0.1, facecolor='white')\n",
    "    plt.close('all')\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "\n",
    "#plot_age_grd((0, age_grd_files[0]))\n",
    "with Pool(10) as p:\n",
    "    r = list(tqdm.tqdm(p.imap(plot_age_grd, enumerate(age_grd_files)), total=len(age_grd_files)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17784a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ffmpeg -y -r 25 -f image2 -i /data2/Anton/lagrangian_v5/age/frame_grd_%04d.png -vcodec libx264 -crf 8 -pix_fmt yuv420p -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" /data2/Anton/lagrangian_v5/age/age_grd.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "929440d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from geodataset.geodataset import GeoDatasetWrite\n",
    "import pyproj\n",
    "\n",
    "class SeaIceAgeDataset(GeoDatasetWrite):\n",
    "    \"\"\" wrapper for netCDF4.Dataset with info about Ice Age products \"\"\"\n",
    "    grid_mapping_variable = 'Lambert_Azimuthal_Equal_Area'\n",
    "    projection = pyproj.Proj(\"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs\")\n",
    "    global_attributes_source = None\n",
    "    global_attributes_title = None\n",
    "\n",
    "    def get_grid_mapping_ncattrs(self):\n",
    "        return dict(\n",
    "            grid_mapping_name = \"lambert_azimuthal_equal_area\" ,\n",
    "            longitude_of_projection_origin = 0. ,\n",
    "            latitude_of_projection_origin = 90. ,\n",
    "            false_easting = 0. ,\n",
    "            false_northing = 0. ,\n",
    "            semi_major_axis = 6378137. ,\n",
    "            inverse_flattening = 298.257223563 ,\n",
    "            proj4_string = \"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs\" ,\n",
    "        )\n",
    "\n",
    "    def set_global_attributes(self, date):\n",
    "        global_attributes = dict(\n",
    "            title = self.global_attributes_title,\n",
    "            summary = \"This climate data record of sea ice age is obtained from coarse resolution ice drift and conentration OSI SAF products. The processing chain features: 1) Lagrangian advection of ice age fractions, 2) Weighted averaging of fractions.\",\n",
    "            topiccategory = \"Oceans ClimatologyMeteorologyAtmosphere\",\n",
    "            keywords = \"Earth Science > Cryosphere > Sea Ice > Sea Ice Motion\\n, Earth Science > Oceans > Sea Ice > Sea Ice Motion\\n, Earth Science > Climate Indicators > Cryospheric Indicators > Sea Ice Motion\\n, Geographic Region > Northern Hemisphere\\n, Vertical Location > Sea Surface\\n, NERSC > Nansen Environmental and Remote Sensing Centre\",\n",
    "            keywords_vocabulary = \"GCMD Science Keywords\",\n",
    "            northernmost_latitude = 90.,\n",
    "            southernmost_latitude = 17.61202,\n",
    "            easternmost_longitude = 180.,\n",
    "            westernmost_longitude = -180.,\n",
    "            geospatial_vertical_min = 0.,\n",
    "            geospatial_vertical_max = 0.,\n",
    "            sensor = \"SSM/I,SSMIS,AMSR-E,AMSR2\",\n",
    "            platform = \"DMSP-F<08,10,11,13,14,15>,DMSP-F<16,17,18>,Aqua,GCOM-W1\",\n",
    "            source = self.global_attributes_source,\n",
    "            time_coverage_start = date.strftime(\"%Y-%m-%dT00:00:00Z\"),\n",
    "            time_coverage_end = (date + dt.timedelta(1)).strftime(\"%Y-%m-%dT00:00:00Z\"),\n",
    "            time_coverage_duration = \"P1D\",\n",
    "            time_coverage_resolution = \"P1D\",\n",
    "            project = \"TARDIS - Norwegian Research Council\",\n",
    "            institution = \"Nansen Environmental and Remote Sensing Centre\",\n",
    "            creator_name = \"NERSC\",\n",
    "            creator_type = \"institution\",\n",
    "            creator_url = \"https://nersc.no\",\n",
    "            creator_email = \"anton.korosov@nersc.no\",\n",
    "            license = \"All intellectual property rights of the Sea Ice Age product belong to NERSC. The use of these products is granted to every user, free of charge. If users wish to use these products, NERSC\\'s copyright credit must be shown by displaying the words \\'Copyright NERSC\\' under each of the products shown. NERSC offers no warranty and accepts no liability in respect of the Sea Ice Age products. NERSC neither commits to nor guarantees the continuity, availability, or quality or suitability for any purpose of, the Sea Ice Age product.\",\n",
    "            references = \"Korosov, A. A., Rampal, P., Pedersen, L. T., Saldo, R., Ye, Y., Heygster, G., Lavergne, T., Aaboe, S., and Girard-Ardhuin, F.: A new tracking algorithm for sea ice age distribution estimation, The Cryosphere, 12, 2073–2085, https://doi.org/10.5194/tc-12-2073-2018, 2018.\",\n",
    "            date_created = \"2023-06-13\",\n",
    "            cdm_data_type = \"Grid\",\n",
    "            spatial_resolution = \"25.0 km grid spacing\",\n",
    "            algorithm = \"lagrangian_sea_ice_age_v2p1\",\n",
    "            geospatial_bounds_crs = \"EPSG:6931\",\n",
    "            contributor_name = \"Anton Korosov, Leo Edel, Laurent Bertino\",\n",
    "            contributor_role = \"Author, Assistant, PrincipalInvestigator\",\n",
    "            naming_authority = \"NERSC\",\n",
    "            Conventions = \"CF-1.7 ACDD-1.3\",\n",
    "            standard_name_vocabulary = \"CF Standard Name Table (Version 78, 21 September 2021)\",\n",
    "            product_name = \"nersc_arctic_sea_ice_age_climate_data_record\",\n",
    "            product_id = \"arctic25km_sea_ice_age_v2p1\",\n",
    "            product_version = \"v2.1\",\n",
    "        )\n",
    "        for key, value in global_attributes.items():\n",
    "            self.setncattr(key, value)\n",
    "\n",
    "    def set_variable(self, vname, data, dims, atts, dtype=np.float32):\n",
    "        \"\"\"\n",
    "        set variable data and attributes\n",
    "        Parameters:\n",
    "        -----------\n",
    "        vname : str\n",
    "            name of new variable\n",
    "        data : numpy.ndarray\n",
    "            data to set in variable\n",
    "        dims : list(str)\n",
    "            list of dimension names for the variable\n",
    "        atts : dict\n",
    "            netcdf attributes to set\n",
    "        dtype : type\n",
    "            netcdf data type for new variable (eg np.float32 or np.double)\n",
    "        \"\"\"\n",
    "        ncatts = {k:v for k,v in atts.items() if k != '_FillValue'}\n",
    "        kw = dict(zlib=True)# use compression\n",
    "        if '_FillValue' in atts:\n",
    "            # needs to be a keyword for createVariable and of right data type\n",
    "            kw['fill_value'] = dtype(atts['_FillValue'])\n",
    "        if 'missing_value' in atts:\n",
    "            # needs to be of right data type\n",
    "            ncatts['missing_value'] = dtype(atts['missing_value'])\n",
    "        dst_var = self.createVariable(vname, dtype, dims, **kw)\n",
    "        ncatts['grid_mapping'] = self.grid_mapping_variable\n",
    "        dst_var.setncatts(ncatts)\n",
    "        dst_var[0] = data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "970c128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sic_cdr_dir = '/Data/sim/data/OSISAF_ice_conc_CDR_v3p0'\n",
    "age_grd_dir = f'{lag_dir}/age_grd'\n",
    "dst_root_dir = f'{lag_dir}/nc'\n",
    "\n",
    "template_file = f'{sic_cdr_dir}/1991/01/ice_conc_nh_ease2-250_cdr-v3p0_199101011200.nc'\n",
    "\n",
    "time_atts = {}\n",
    "with Dataset(template_file) as template_ds:\n",
    "    xc = template_ds['xc'][:]\n",
    "    yc = template_ds['yc'][:]\n",
    "    lon = template_ds['lon'][:]\n",
    "    lat = template_ds['lat'][:]\n",
    "    time_var = template_ds['time']\n",
    "    for key in time_var.ncattrs():\n",
    "        time_atts[key] = time_var.getncattr(key)\n",
    "    status_flag = template_ds['status_flag'][0]\n",
    "\n",
    "status_flag = (status_flag == 1).astype(int)\n",
    "\n",
    "age_atts = dict(\n",
    "    standard_name = 'age_of_sea_ice',\n",
    "    long_name = 'Weighted Average of Sea Ice Age',\n",
    "    name = 'sia',\n",
    "    ancillary_variables = 'status_flag',\n",
    "    comment = 'The weighted average is computed over all available fractions.',\n",
    ")\n",
    "\n",
    "conc_atts = dict(\n",
    "    long_name = \"Concentration of $Numeral$ Year Sea Ice\",\n",
    "    name = \"conc_$YEAR$yi\",\n",
    "    units = \"1\",\n",
    "    standard_name = \"$numeral$_year_sea_ice_area_fraction\",\n",
    ")\n",
    "\n",
    "status_atts = dict(\n",
    "    long_name = \"status flag array for sea ice age\",\n",
    "    standard_name = \"age_of_sea_ice status_flag\",\n",
    "    valid_min = np.byte(0),\n",
    "    valid_max = np.byte(2),\n",
    "    grid_mapping = \"Lambert_Azimuthal_Grid\",\n",
    "    coordinates = \"lat lon\",\n",
    "    flag_masks = (np.byte(0), np.byte(1), np.byte(2)),\n",
    "    flag_meanings = \"nominal land invalid\",\n",
    "    flag_descriptions = (\"\\n\"\n",
    "        \"flag = 0: Nominal retrieval by the SIA algorithm\\n\"\n",
    "        \"flag = 1: Position is over land\\n\"\n",
    "        \"flag = 2: Pixel is invalid\\n\"),\n",
    ")\n",
    "\n",
    "numerals = [None, 'first', 'second', 'third', 'fourth', 'fifth', 'sixth', 'seventh', 'eighth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fe0b9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12162 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12162/12162 [00:10<00:00, 1130.98it/s] \n"
     ]
    }
   ],
   "source": [
    "force = False\n",
    "age_grd_files = sorted(glob.glob(f'{age_grd_dir}/*/age_????????_grd.npz'))\n",
    "source_CDR = \"Global Sea Ice Drift Climate Data Record Version 1 from the EUMETSAT OSI SAF, \\n Sea Ice Concentration Climate Data Record Version 3 from the EUMETSAT OSI SAF\"\n",
    "source_iCDR = \"Daily Low Resolution Sea Ice Displacement from OSI SAF EUMETSAT (OSI-405), \\n Sea Ice Concentration Interim Climate Data Record Version 3 from the EUMETSAT OSI SAF\"\n",
    "\n",
    "title_CDR = \"Arctic Sea Ice Age Climate Data Record Version 2.1 from NERSC\"\n",
    "title_iCDR = \"Arctic Sea Ice Age Interim Climate Data Record Version 2.1 from NERSC\"\n",
    "\n",
    "iCDR_start_date = dt.datetime(2021,1,1)\n",
    "\n",
    "def export_netcdf(age_grd_file):\n",
    "    age_grd_date = dt.datetime.strptime(os.path.basename(age_grd_file).split('_')[1], '%Y%m%d')\n",
    "    dst_dir = age_grd_date.strftime(f'{dst_root_dir}/%Y')\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    dst_file = age_grd_date.strftime(f'{dst_dir}/arctic25km_sea_ice_age_v2p0_%Y%m%d.nc')\n",
    "    if os.path.exists(dst_file) and not force:\n",
    "        return\n",
    "\n",
    "    time_data = np.array([(dt.datetime(age_grd_date.year, age_grd_date.month, age_grd_date.day, 12) - dt.datetime(1978,1,1)).total_seconds()], float)\n",
    "\n",
    "    age_grd = dict(np.load(age_grd_file))\n",
    "    age_grd_vars = list(age_grd.keys())\n",
    "    status_flag[(status_flag == 0) * np.isnan(age_grd['age'])] = 2\n",
    "\n",
    "    with SeaIceAgeDataset(dst_file, 'w') as ds:\n",
    "        if age_grd_date < iCDR_start_date:\n",
    "            ds.global_attributes_source = source_CDR\n",
    "            ds.global_attributes_title = title_CDR\n",
    "        else:\n",
    "            ds.global_attributes_source = source_iCDR\n",
    "            ds.global_attributes_title = title_iCDR\n",
    "\n",
    "        ds.set_projection_variable()\n",
    "        ds.set_xy_dims(xc*1000, yc*1000)\n",
    "        #ds.set_lonlat(lon, lat)\n",
    "        ds.set_global_attributes(age_grd_date)\n",
    "        ds.set_time_variable(time_data, time_atts)\n",
    "\n",
    "        ds.set_variable('sia', age_grd['age'], ('time', 'y', 'x'), age_atts, dtype=np.float32)\n",
    "\n",
    "        for age_grd_var in age_grd_vars:\n",
    "            if 'fraction' in age_grd_var:\n",
    "                year = age_grd_var.split('_')[1][0]\n",
    "                numeral = numerals[int(year)]\n",
    "                frac_atts = {}\n",
    "                for key, value in conc_atts.items():\n",
    "                    frac_atts[key] = value.replace('$Numeral$', numeral.title()).replace('$YEAR$', year).replace('$numeral$', numeral)\n",
    "                ds.set_variable(frac_atts['name'], age_grd[age_grd_var][None]/100., ('time', 'y', 'x'), frac_atts, dtype=np.float32)\n",
    "\n",
    "        ds.set_variable('status_flag', status_flag, ('time', 'y', 'x'), status_atts, dtype=np.byte)\n",
    "\n",
    "export_netcdf(age_grd_files[0])\n",
    "export_netcdf(age_grd_files[-1])\n",
    "\n",
    "with Pool(4) as p:\n",
    "    r = list(tqdm.tqdm(p.imap(export_netcdf, age_grd_files, chunksize=10), total=len(age_grd_files)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
