{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a28168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.ndimage import uniform_filter\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from remeshing import get_area\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import get_mesh_files, fill_gaps\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sid_data(ifile, mesh_src_file):\n",
    "    with np.load(ifile) as d:\n",
    "        u = d['u']\n",
    "        v = -d['v']\n",
    "        sid_unc = d['sid_unc']\n",
    "    u[np.isnan(u)] = 0\n",
    "    v[np.isnan(v)] = 0\n",
    "    with np.load(mesh_src_file) as d:\n",
    "        x0 = d['x']\n",
    "        y0 = d['y']\n",
    "        t0 = d['t']\n",
    "    return u, v, sid_unc, x0, y0, t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter size (Gaissian filter was 5, but weights are smaller for larger distances)\n",
    "size = 3\n",
    "\n",
    "# should be 2210 to cover 6 years\n",
    "n_steps = 2210 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07325a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia_dir = 'data2/Anton/sia/cdr_1991_2023'\n",
    "mesh_dir = f'{sia_dir}/mesh'\n",
    "unc_dir = f'{sia_dir}/unc'\n",
    "sid_dir = 'data2/Anton/sia_sid_cdr_postproc'\n",
    "ifiles = sorted(glob.glob(f'{sid_dir}/*/*npz'))\n",
    "idates = [datetime.strptime(os.path.basename(ifile).split('-')[-1].split('.')[0], '%Y%m%d%H%M%S')\n",
    "          for ifile in ifiles]\n",
    "\n",
    "mesh_init_file = 'mesh_arctic_ease_25km_max7.npz'\n",
    "xc = np.load(mesh_init_file)['xc']\n",
    "yc = np.load(mesh_init_file)['yc']\n",
    "mask = np.load(mesh_init_file)['mask']\n",
    "mask_f = gaussian_filter(mask.astype(float), 1, truncate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eed238",
   "metadata": {},
   "source": [
    "# Accumulate and save SID uncertainty\n",
    "$\\sigma_{i} = \\sqrt{<\\sigma_{i-1}^2> + \\sigma_S^2}$\n",
    "\n",
    "$\\sigma_S$ - uncertainty of smoothed SID from CDR\n",
    "\n",
    "$\\sigma_{i-1}$ - uncertainty from previous step\n",
    "\n",
    "$<>$ - advection operation\n",
    "\n",
    "$\\sigma_S = \\frac{\\sqrt{\\sum_j^N{\\sigma_{Oj}}}}{\\sqrt{N}}$\n",
    "\n",
    "$\\sigma_{Oj}$ - uncertaimty in neighbour $j$\n",
    "\n",
    "$N$ - number of neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_indices = [i for i,j in enumerate(idates) if j.year > 2018 and j.month == 9 and j.day == 5]\n",
    "start_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ac097",
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_idx in start_indices:\n",
    "    stop_idx = min(start_idx + n_steps, len(idates))\n",
    "    unc_sid_sum = None\n",
    "    x = None\n",
    "    start_date = idates[start_idx]\n",
    "    odir = f'{unc_dir}/{start_date.year}'\n",
    "    os.makedirs(odir, exist_ok=True)\n",
    "    for i in tqdm(range(start_idx, stop_idx), total=n_steps):\n",
    "        ifile = ifiles[i]\n",
    "        idate = idates[i]\n",
    "        ofile = f'{odir}/unc_sid_{start_date.strftime(\"%Y%m%d\")}_{idate.strftime(\"%Y%m%d\")}.npz'\n",
    "        if os.path.exists(ofile):\n",
    "            unc_sid_sum = np.load(ofile)['unc_sid']\n",
    "            continue\n",
    "\n",
    "        mesh_file, mesh_dst_file = get_mesh_files(idate, mesh_dir, mesh_init_file)\n",
    "        u_grd, v_grd, unc_sid_grd, x, y, t = load_sid_data(ifile, mesh_file)\n",
    "        unc_sid_fil = fill_gaps(unc_sid_grd, np.isnan(unc_sid_grd), distance=144)\n",
    "\n",
    "        # compute uncertainty of drift field after smoothing\n",
    "        unc_sid_smt = uniform_filter(unc_sid_fil**2, size=size) / size\n",
    "        unc_sid_smt[u_grd == 0] = 0\n",
    "\n",
    "        # interpolate uncertainty to mesh\n",
    "        unc_sid = RectBivariateSpline(xc[1:-1:3], yc[1:-1:3], unc_sid_smt[::-1], kx=1, ky=1)(y[t].mean(axis=1), x[t].mean(axis=1), grid=False)\n",
    "\n",
    "        if unc_sid_sum is None:\n",
    "            # first time step\n",
    "            unc_sid_sum = np.array(unc_sid)\n",
    "        else:\n",
    "            # advect unc_sid_sum (from previous time step)\n",
    "            src2dst = np.load(mesh_file)['src2dst']\n",
    "            weights = np.load(mesh_file)['weights']\n",
    "            unc_sid_sum_pro = np.zeros(src2dst[:,1].max()+1)\n",
    "            np.add.at(unc_sid_sum_pro, src2dst[:,1], unc_sid_sum[src2dst[:,0]] * weights)\n",
    "            # compute uncertainty of drift field after advection\n",
    "            unc_sid_sum = np.hypot(unc_sid, unc_sid_sum_pro)\n",
    "        np.savez(ofile, unc_sid=unc_sid_sum)\n",
    "\n",
    "    print(start_date)\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    trp0 = axs.tripcolor(x, y, t, unc_sid_sum, cmap='jet')\n",
    "    plt.colorbar(trp0, ax=axs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b14a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unc_sid_sum = None\n",
    "unc_sid_sum_all = {}\n",
    "\n",
    "unc_sic_sum = None\n",
    "unc_sic_sum_all = {}\n",
    "\n",
    "sic_min = None\n",
    "\n",
    "unc_sic_sid_all = {}\n",
    "\n",
    "n_steps = 120\n",
    "\n",
    "# 2020\n",
    "#start = 10840\n",
    "#stop = start + n_steps\n",
    "\n",
    "# 1991\n",
    "start = 247\n",
    "stop = start + n_steps\n",
    "\n",
    "\n",
    "for i in tqdm(range(start, stop), total=n_steps):\n",
    "    ifile = ifiles[i]\n",
    "    idate = idates[i]\n",
    "    #print(ifile, idate)\n",
    "\n",
    "    mesh_file, mesh_dst_file = get_mesh_files(idate, mesh_dir, mesh_init_file)\n",
    "    u0, v0, tri0 = load_data(ifile, mesh_file)\n",
    "\n",
    "    # load uncertainty of drift field\n",
    "    sid_file = f'/Data/sim/data/OSISAF_ice_drift_CDR_v1p0_merged/{idate.strftime(\"%Y\")}/{idate.strftime(\"%m\")}/ice_drift_nh_ease2-750_cdr-v1p0_24h-{idate.strftime(\"%Y%m%d\")}1200.nc'\n",
    "    with Dataset(sid_file) as dds:\n",
    "        uncrt = dds['uncert_dX_and_dY'][0].filled(np.nan)\n",
    "    uncrt_filled = fill_gaps(uncrt, np.isnan(uncrt), distance=144)\n",
    "\n",
    "    # compute uncertainty of drift field after smoothing\n",
    "    uncrt_mean = uniform_filter(uncrt_filled**2, size=size) / size\n",
    "    uncrt_mean[u0 == 0] = 0\n",
    "\n",
    "    # interpolate uncertainty to mesh\n",
    "    x0, y0, t0 = tri0.x, tri0.y, tri0.triangles\n",
    "    unc_sid0 = RectBivariateSpline(xc[1:-1:3], yc[1:-1:3], uncrt_mean[::-1], kx=1, ky=1)(y0[t0].mean(axis=1), x0[t0].mean(axis=1), grid=False)\n",
    "\n",
    "    if unc_sid_sum is None:\n",
    "        # first time step\n",
    "        unc_sid_sum = np.array(unc_sid0)\n",
    "    else:\n",
    "        # advect unc_sid_sum (from previous time step)\n",
    "        src2dst = np.load(mesh_file)['src2dst']\n",
    "        weights = np.load(mesh_file)['weights']\n",
    "        unc_sid_sum_pro = np.zeros(src2dst[:,1].max()+1)\n",
    "        np.add.at(unc_sid_sum_pro, src2dst[:,1], unc_sid_sum[src2dst[:,0]] * weights)\n",
    "        # compute uncertainty of drift field after advection\n",
    "        unc_sid_sum = np.hypot(unc_sid0, unc_sid_sum_pro)\n",
    "\n",
    "    unc_sid_sum_all[idate] = unc_sid_sum\n",
    "\n",
    "    # load uncertainty of sea ice concentration\n",
    "    sic_file_mask = f'/Data/sim/data/OSISAF_ice_conc_CDR_v3p0/{idate.strftime(\"%Y\")}/{idate.strftime(\"%m\")}/ice_conc_nh_ease2-*_{idate.strftime(\"%Y%m%d\")}1200.nc'\n",
    "    sic_file = glob.glob(sic_file_mask)[0]\n",
    "    with Dataset(sic_file) as dds:\n",
    "        uncrt_sic = dds['total_standard_uncertainty'][0].filled(np.nan)\n",
    "    uncrt_sic_filled = fill_gaps(uncrt_sic, np.isnan(uncrt_sic), distance=144)\n",
    "    \n",
    "    # interpolate SIC uncertainty to mesh\n",
    "    unc_sic0 = RectBivariateSpline(xc, yc, uncrt_sic_filled[::-1], kx=1, ky=1)(y0[t0].mean(axis=1), x0[t0].mean(axis=1), grid=False)\n",
    "\n",
    "    sic_file = mesh_file.replace('mesh', 'sic')\n",
    "    c0 = np.load(sic_file)['c']\n",
    "\n",
    "    if unc_sic_sum is None:\n",
    "        # first time step\n",
    "        unc_sic_sum = np.array(unc_sic0)\n",
    "        sic_min = np.array(c0)\n",
    "    else:\n",
    "        # advect unc_sic_sum (from previous time step)\n",
    "        unc_sic_sum_pro = np.zeros(src2dst[:,1].max()+1)\n",
    "        np.add.at(unc_sic_sum_pro, src2dst[:,1], unc_sic_sum[src2dst[:,0]] * weights)\n",
    "        \n",
    "        # advect sic_min from previous time step\n",
    "        sic_min_pro = np.zeros(src2dst[:,1].max()+1)\n",
    "        np.add.at(sic_min_pro, src2dst[:,1], sic_min[src2dst[:,0]] * weights)\n",
    "\n",
    "        # keep uncertainty of the minimal value of SIC\n",
    "        min_sic_ids = c0 < sic_min_pro\n",
    "        unc_sic_sum = unc_sic_sum_pro\n",
    "        unc_sic_sum[min_sic_ids] = unc_sic0[min_sic_ids]\n",
    "        \n",
    "        # keep min ice concentration\n",
    "        sic_min = np.min([sic_min_pro, c0], axis=0)\n",
    "        # sum up uncertainties of SIC field\n",
    "        #unc_sic_sum = np.hypot(unc_sic0, unc_sic_sum_pro)\n",
    "\n",
    "    # compute uncertainty of SIC field as STD in the area defined by the uncert of drift field\n",
    "    el_size = get_area(x0, y0, t0)**0.5\n",
    "    sid_unc_rel_to_el_size = np.abs(unc_sid_sum - el_size) / el_size\n",
    "\n",
    "    unc_sic_sid = np.zeros_like(unc_sic_sum)\n",
    "    el_size_mean = el_size.mean()\n",
    "\n",
    "    min_rel_size_factor = 2\n",
    "    min_rel_sizes = [2, 4, 6, 8, 10, 12]\n",
    "\n",
    "    for min_rel_size in min_rel_sizes:\n",
    "        min_abs_size = el_size_mean * min_rel_size * min_rel_size_factor\n",
    "\n",
    "        x0el = x0[t0].mean(axis=1)\n",
    "        y0el = y0[t0].mean(axis=1)\n",
    "\n",
    "        uncert_elems = np.nonzero(\n",
    "            (sid_unc_rel_to_el_size >= min_rel_size) * \n",
    "            (sid_unc_rel_to_el_size < min_rel_size+min_rel_size_factor)\n",
    "            )[0]\n",
    "        if len(uncert_elems) == 0:\n",
    "            continue\n",
    "        \n",
    "        x_unc_sid = x0el[uncert_elems]\n",
    "        y_unc_sid = y0el[uncert_elems]\n",
    "        tree_unc = cKDTree(np.c_[x_unc_sid, y_unc_sid])\n",
    "        tree_all = cKDTree(np.c_[x0el, y0el])\n",
    "        indices = tree_unc.query_ball_tree(tree_all, min_abs_size)\n",
    "\n",
    "        for i, indx in enumerate(indices):\n",
    "            if len(indx) > 0:\n",
    "                unc_sic_sid[uncert_elems[i]] = c0[indx].std()\n",
    "    \n",
    "    unc_sic_sum_all[idate] = unc_sic_sum\n",
    "    unc_sic_sid_all[idate] = unc_sic_sid\n",
    "\n",
    "    #fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    #axs[0].tripcolor(x0, y0, t0, unc_sid_sum, cmap='jet', clim=[0, 30])\n",
    "    #axs[0].set_title('Drift uncertainty')\n",
    "    #axs[1].tripcolor(x0, y0, t0, unc_sic_sum, cmap='jet', clim=[0, 50])\n",
    "    #axs[1].set_title('SIC uncertainty')\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f4be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(24, 6))\n",
    "trp0 = axs[0].tripcolor(x0, y0, t0, unc_sid_sum, cmap='jet')\n",
    "plt.colorbar(trp0, ax=axs[0])\n",
    "trp1 = axs[1].tripcolor(x0, y0, t0, unc_sic_sum, cmap='jet')\n",
    "plt.colorbar(trp1, ax=axs[1])\n",
    "trp2 = axs[2].tripcolor(x0, y0, t0, unc_sic_sid, cmap='jet')\n",
    "plt.colorbar(trp2, ax=axs[2])\n",
    "trp3 = axs[3].tripcolor(x0, y0, t0, \n",
    "                        np.hypot(\n",
    "                            unc_sic_sum,\n",
    "                            unc_sic_sid), cmap='jet')\n",
    "plt.colorbar(trp3, ax=axs[3])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40391cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
